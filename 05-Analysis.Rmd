#Analysis Code for National NOS

ObservationCount = 1st minute + 2nd minute (i.e., silent listening period). 

Install the required packages (some of these may no longer be needed)
```{r install packages, echo=FALSE, message=FALSE}

require(naturecounts)
require(lubridate)
require(reshape)
require(ggplot2)
require(mgcv) #used for the GAM spline
require(robustHD)
require(readr)
library(RColorBrewer)
library(tidyverse)
library(rgdal)
library(sp)
library(rgdal)
library(spdep)
library(sf)
library(concaveman)
library(scales)
#install.packages("INLA", repos=c(getOption("repos"), 
#        INLA="https://inla.r-inla-download.org/R/testing"), dep=TRUE)
library(INLA)
#library(brinla)
library(inlabru)
library(leaflet)

source("00-setup.R")

```

Code to read and append the relevant files from the out directory. This is ObservationCount for the national trends. 

```{r pull multiple files, echo=FALSE, message=FALSE}

#Read file that was created in ArcGIS by spatially joining the Events layer (created in the data manipulation code) with the grid cells spatial layer. Need to manual rename columns before importing into R

#Contains Grid_ID, RouteID, CollectorNumber, and survey year.  
grid<-read.csv("ATOWL_dat.csv")
grid<-grid %>% distinct() #Manually remove duplicates. This is added because there were duplicates due to some records haivng missing BCR. This has been fixed in the national nos data cleaning step, but was not remapped for cell assignment. 

max.yr<-2019

#Read in the events data then filer for just ATOWLS 
require(plyr)

out.dir<-"output/2019"
my.files<-list.files(path = out.dir, patter ="*ObservationCount1.csv", full.name=TRUE)
obs<-ldply(my.files, read.csv)

my.files<-list.files(path = out.dir, patter ="*EventData.csv", full.name=TRUE)
event.data<-ldply(my.files, read.csv)

#write out full events for plotting in ArcGIS
#write.csv(event.data, paste(out.dir, "FullEventData.csv", sep=""))

event.data<-event.data %>% filter (StateProvince %in% c("NB", "NS", "PE")) %>%  droplevels()

#Need to remove route NS050. Form seems to be assigned to both NS and PE. Was not fixed in underlying data.
event.data<-event.data %>% filter(RouteIdentifier!="NS050") %>% droplevels()


write.csv(event.data, paste(out.dir, "ATOWLS.FullEventData.csv", sep=""))

obs<-obs %>% filter (StateProvince %in% c("NB", "NS", "PE")) %>% droplevels()
obs<-obs %>% filter(RouteIdentifier!="NS050") %>% droplevels()

#join grid to event so that we have the needed cell id for the analysis
event.data<-left_join(event.data, grid, by=c("RouteIdentifier", "survey_year", "CollectorNumber"))


detach(package:plyr) #detach or this will cause an issue with dplyr

```

Create summary stats
```{r sumstat, echo=FALSE, message=FALSE}

#Filter out non target species. 
obs <- obs %>% filter (CommonName %in% c("Barred Owl", "Boreal Owl", "Great Gray Owl", "Great Horned Owl", "Northern Saw-whet Owl", "Eastern Screeh-Owl", "Western Screech-Owl", "Long-eared Owl", "Short-eared Owl", "Northern Hawk Owl", "Northern Pygmy-Owl", "Snowy Owl", "Barn Owl", "Flammulated Owl"))

#species by protocol summary. Check for missclassifications
sp.prot<-obs %>% select(CommonName, collection, ProtocolCode, StateProvince) %>% distinct()
sp.prot$count<-"x"
sp.prot<-cast(sp.prot, collection +StateProvince+ ProtocolCode~CommonName, value="count")

```

```{r anal.dat, echo = TRUE, message = FALSE}

#select desired data columns for analysis
obs<-obs %>% select("CommonName", "species_id", "RouteIdentifier", "SiteCode", "collection", "ProtocolCode", "survey_year", "CollectorNumber", "ObservationCount1")

```

We are ready to develop the species-specific analysis loop

```{r sp.loop, echo = TRUE, message = FALSE}

## Generate species list for analysis. The species that make the cut will vary on province based on the data manipulation
species.list <- unique(obs$CommonName)

for(m in 1:length(species.list)) {

 m<-3 #for testing each species
   
  sp.data <-NULL 
  sp.data <- filter(obs, CommonName == species.list[m]) %>%
      droplevels()
  
  print(paste("Currently analyzing species ", m, "/", species.list[m], sep = "")) 

##-----------------------------------------------------------
#zero fill by merging with the events dataframe. 
sp.data <- left_join(event.data, sp.data, by = c("RouteIdentifier", "survey_year", "CollectorNumber")) %>% mutate(ObservationCount1 = replace(ObservationCount1, is.na(ObservationCount1), 0))

##----------------------------------------------------------
#Observations per route summary
route.sum<-sp.data %>% group_by(survey_year, RouteIdentifier) %>% summarise(count = sum(ObservationCount1))
route.sum<-cast(route.sum, RouteIdentifier~survey_year, value="count")

#Observations per grid summary
grid.sum<-sp.data %>% group_by(survey_year, grid_id) %>% summarise(count = sum(ObservationCount1))
grid.sum<-cast(grid.sum, grid_id~survey_year, value="count")  

##-----------------------------------------------------------
# Limit to species observed at least once per route 
# Summarize survey site to determine which species have been observed at least once (looking at the total count column) those with sum <= 1 across all survey years will be dropped from analysis (implies never observed on a route (i.e., outside range or inappropraite habitat))

  site.summ <- melt(sp.data, id.var = "RouteIdentifier",	measure.var = "ObservationCount1")
  site.summ <- cast(site.summ, RouteIdentifier ~ variable,	fun.aggregate="sum")
  site.sp.list <- unique(subset(site.summ, select = c("RouteIdentifier"), ObservationCount1 >= 1))

# Limit raw data to these species, i.e., those that were observed at least once on a route 
  sp.data <- merge(sp.data, site.sp.list, by = c("RouteIdentifier"))

# Create summary of routes with owls detected per province  
  sp.route.sum<-sp.data %>% group_by(StateProvince) %>% summarise(p.route = n_distinct(RouteIdentifier))
  sp.route.sum$Species<-species.list[m]
  
write.table(sp.route.sum, paste(out.dir, "SpeciesRouteCountSummary.csv", sep="."), row.names = FALSE, append = TRUE, quote = FALSE, sep = ",", col.names = TRUE)

##-----------------------------------------------------------
# Count the number of owls per route as the response varaible. The number of stop on a route can be used as a covarite in the model to control for route level effort. Not used in Atlantic Canada because route are mostly complete. 
sp.data<-sp.data %>% group_by(RouteIdentifier, survey_year, CollectorNumber, grid_id, nstop, StateProvince, bcr, latitude, longitude) %>% summarise(count1=sum(ObservationCount1))

#-----------------------------------------------------------   
# Create the offset variable which is the number of routes run in a year to control for changes in effort over time. Previously I was using the log transformed nroute as an offset (E), however, this assumes that doubling the number of routes will double the number of owls counted, which may not hold true. The other option is to add nroute as a co-variate in the model (Zuur 2018 pg 445). 

# The spatially explicit approach pools counts across geographic stratum and deals with the issue of routes becoming active or inactive over time, thus temporal variability in route level effort. 

#nroute<-NULL
#nroute<-sp.data%>% group_by(survey_year) %>% summarise(nroute=n_distinct(RouteIdentifier))
#sp.data<-left_join(nroute, sp.data, by="survey_year")

##-----------------------------------------------------------  
#Create a first-year observer effect varaible 
#did not use this in present analysis since it is not know to effect owl could like those of passerine

#library(plyr)
#obseff<-NULL #clear previous
#obseff<- ddply(sp.data,~CollectorNumber,function(d)d[which.min#(d$survey_year),]) 
#obseff$ObsEffect<-1
#obseff<-obseff %>% select(RouteIdentifier, survey_year, CollectorNumber, ObsEffect)

#sp.data<-left_join(sp.data, obseff, by=c("RouteIdentifier", "survey_year", "CollectorNumber"))
#sp.data<-sp.data %>% mutate(ObsEffect = replace(ObsEffect, is.na(ObsEffect), 0)) 

#detach plyr once finished with it because it has a tendancy to mess up the dplyr packages  
#detach(package:plyr)
#library(dplyr) #sometime this will need reinstalled here(?)

##-----------------------------------------------------------  
#create a route-observer effect
sp.data$routeobs <- paste0(sp.data$RouteIdentifier, "-", sp.data$CollectorNumber)

##----------------------------------------------------------- 
#standardize year to 2019   
sp.data <- sp.data %>% mutate(std_yr = survey_year - max.yr)

##-----------------------------------------------------------

#Get grid data for plotting
#ATOWLS_Point <- readOGR(dsn="C:/Users/dethier/Documents/ethier-scripts/Atlantic-NOS/Data", layer="ATOWLS_Point") 
# NAD83 (EPSG:4269) 
#head(ATOWLS_Point@data) #"+proj=longlat +datum=NAD83 +no_defs"

#Could use the leaflets package to map routes? Might be good for the web output.
#map<-leaflet() %>% 
#    addProviderTiles(providers$OpenStreetMap.Mapnik) %>% 
#    addCircleMarkers(data=ATOWLS_Point) 

#xy <- data.frame(X = ATOWLS_Point@data$longitude, Y = ATOWLS_Point@data$latitude)
#coordinates(xy) <- c("X", "Y")
#proj4string(xy) <- CRS("+proj=longlat +datum=NAD83 +no_defs")  ## for example
#assign to the same projection at the polygon feature
#ATOWLS_pt <- spTransform(xy, CRS("+proj=aea +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs"))

ATOWLS_Grid <- readOGR(dsn="C:/Users/dethier/Documents/ethier-scripts/Atlantic-NOS/Data", layer="ATGrid_50Kv4")
names(ATOWLS_Grid)[19] <- "grid_id" #head(ATOWLS_Grid@data) #"+proj=aea +lat_0=40 +lon_0=-96 +lat_1=20 +lat_2=60 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs"

#nos_na_grid <- readOGR(dsn="C:/Users/dethier/Documents/ethier-scripts/Atlantic-NOS/Data", layer="nos_na_grid")
#nos_na_grid$na_id <- nos_na_grid$id; head(nos_na_grid@data)
#plot(nos_na_grid)
#plot(ATOWLS_Grid, col="red", add=T)
#grid1<-NULL
#grid1 <- as(ATOWLS_Grid, "sf")
#plot(ATOWLS_pt, col="blue", add=T) #this did not work correctly due to an issue with projection
#point1<-as(ATOWLS_pt, "sf")

grid_key <- unique(sp.data[, c("grid_id", "bcr", "StateProvince")])
row.names(grid_key) <- NULL

#summarize routes per grid ----------------------------------
#how many routes per occupied grid cell
#names(sp.data)
route_per_cell <- sp.data %>%
  ungroup %>% 
  dplyr::select(RouteIdentifier, grid_id, longitude, latitude) %>%
  arrange(grid_id) %>% unique() %>%
  mutate(occupied=ifelse(is.na(longitude), 0, 1)) %>% #already removed routes without the species
  group_by(grid_id) %>%
  summarise(number_routes=sum(occupied))

#ggplot(route_per_cell, aes(number_routes)) +
#  geom_histogram(breaks=c(0:15), fill="gray60", color="white") +
#  xlab("Number of routes per grid cell") + ylab("Count")

#summary(route_per_cell)

#print route_per_cell output table. This is also a map output.
write.csv(route_per_cell, paste(out.dir, species.list[m], ".route_per_cell.csv", sep=""))

##-----------------------------------------------------------
##Make neighbors
nb1 <- poly2nb(ATOWLS_Grid, row.names=ATOWLS_Grid$grid_id); nb1

#Output with the new 50K grid
#Neighbour list object:
#Number of regions: 241 
#Number of nonzero links: 1534 
#Percentage nonzero weights: 2.641139 
#Average number of links: 6.365145 

is.symmetric.nb(nb1, verbose = FALSE, force = TRUE)
nb2INLA("nb1.graph", nb1)
nb1.adj <- paste(getwd(),"/nb1.graph", sep="")
g1 <- inla.read.graph("nb1.graph")
#plot(nb1, coordinates(ATOWLS_Grid), col="red", cex=0.5)

##-----------------------------------------------------------
#Index variable
#where i = grid cell, k = route, t = year
sp.data$eps_i <- sp.data$alpha_i <- as.integer(factor(sp.data$grid_id))

sp.data$tau_i <- sp.data$eps_i
sp.data$kappa_k <- as.integer(factor(sp.data$routeobs))
sp.data <- arrange(sp.data, grid_id, std_yr)
n_routeobs <- max(sp.data$kappa_k, na.rm=T)
n_cells <- max(sp.data$alpha_i, na.rm=T)

#Specify model with year-cell effects so that we can predict the annual index value for each cell
#Rather then using the cell ID use the factor assigned previously to alpha_i
sp.data$gamma_ij <- paste0(sp.data$alpha_i, "-", sp.data$survey_year)

##-----------------------------------------------------------
# make and run model 
# formula for the NB
form1 <- count1 ~ -1 + # remove grand mean
  # cell ICAR random intercepts
  f(alpha_i, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # cell ICAR random effort slopes for nstops
  # not using effort correction for AT dataset alone
#  f(eps_i, nstop, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
#    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # cell ICAR random year slopes
  f(tau_i, std_yr, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # random route-observer intercepts
  f(kappa_k, model="iid", constr=TRUE,
    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
 # cell-year effect
  f(gamma_ij, model="iid", constr=TRUE, 
   hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01))))

##-----------------------------------------------------------
# make and run model 
# formula for the overdispersed Poisson (this did not improve the overdispersion)
#form2 <- count1 ~ -1 + # remove grand mean
  # cell ICAR random intercepts
#  f(alpha_i, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
#    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # cell ICAR random effort slopes for nstops
  # not using effort correction for AT dataset alone
#  f(eps_i, nstop, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
#    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # cell ICAR random year slopes
#  f(tau_i, std_yr, model="besag", graph=g1, constr=FALSE, scale.model=TRUE,
#    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
  # random route-observer intercepts
#  f(kappa_k, model="iid", constr=TRUE,
#    hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
 # cell-year effect
#  f(gamma_ij, model="iid", constr=TRUE, 
#   hyper = list(prec = list(prior = "pc.prec", param = c(1, 0.01)))) +
 # Overdispersion  
#  f(id.iid, model="iid")

##-----------------------------------------------------------
#Get results
out1<- inla(form1, family="nbinomial", data=sp.data,
            control.compute=list(cpo=T, config=T, dic=TRUE),
            control.inla=list(strategy="adaptive",
                              int.strategy="auto"),
            num.threads=3,
            verbose=T)

#Get results
#out2<- inla(form2, family="nbinomial", 
#            data = data.frame(sp.data, id.iid = 1:nrow(sp.data)),
#            control.compute=list(cpo=T, config=T, dic=TRUE),
#            control.inla=list(strategy="adaptive",
#                              int.strategy="auto"),
#            num.threads=3,
#            verbose=T)


# view summaries
#summary(out1, digits=3)

random.out<-out1$summary.hyperpar[,c("mean", "sd", "0.025quant", "0.975quant")]
random.out<-signif(random.out, digits = 4)
random.out$Species <- species.list[m]
names(random.out)[1:5] <- c("mean", "SD", "0.025quant", "0.975quant", "Speices")
  
write.table(random.out, paste(out.dir, "Random_Summary.csv", sep="."), row.names = FALSE, append = TRUE, quote = FALSE, sep = ",", col.names = TRUE)

##Remove cells with no routes

cells_with_counts <- unique(sp.data$alpha_i[which(!is.na(sp.data$count1))])

# get alpha summaries
alph <- exp(out1$summary.random$alpha_i$`0.5quant`[cells_with_counts])
alph_ll <- exp(out1$summary.random$alpha_i$`0.025quant`[cells_with_counts])
alph_ul <- exp(out1$summary.random$alpha_i$`0.975quant`[cells_with_counts])
alph_iw <- alph_ul - alph_ll
hist(alph); summary(alph)
hist(alph_ll); summary(alph_ll)
hist(alph_ul); summary(alph_ul)

# get epsilon summaries
#eps <- out1$summary.random$eps_i$`0.5quant`[cells_with_counts]
#eps_ll <- out1$summary.random$eps_i$`0.025quant`[cells_with_counts]
#eps_ul <- out1$summary.random$eps_i$`0.975quant`[cells_with_counts]
#eps_iw <- eps_ul - eps_ll
#hist(eps); summary(eps); round(sum(eps<1)/length(eps), 2)
#hist(eps_ll); summary(eps_ll)
#hist(eps_ul); summary(eps_ul)
#round(sum(eps_ll<=1 & eps_ul>=1)/length(eps_ll), 2)
#round(sum(eps_ll<=0 & eps_ul>=0)/length(eps_ll), 2)
#cor.test(eps, alph, method="spearman")

# get tau summaries
tau <- (exp(out1$summary.random$tau_i$`0.5quant`[cells_with_counts])
        - 1) * 100
tau_ll <- (exp(out1$summary.random$tau_i$`0.025quant`[cells_with_counts])
           - 1) * 100
tau_ul <- (exp(out1$summary.random$tau_i$`0.975quant`[cells_with_counts])
           - 1) * 100
tau_iw <- tau_ul - tau_ll
hist(tau); summary(tau); round(sum(tau>=0)/length(tau), 2)
hist(tau_ll); summary(tau_ll)
hist(tau_ul); summary(tau_ul)
hist(tau_iw); summary(tau_iw)
round(sum(tau_ll<=0 & tau_ul<=0)/length(tau_ll), 2)
round(sum(tau_ll>=0 & tau_ul>=0)/length(tau_ll), 2)
cor.test(alph, tau, method="spearman")

##-----------------------------------------------------------
#Goodness of fix (GOF)
sum(out1$cpo$failure, na.rm=T)
-2 * sum(log(out1$cpo$cpo[out1$cpo$failure==0]), na.rm=T)
pit1 <- data.frame(PIT=out1$cpo$pit) %>%
  filter(out1$cpo$pit<0.99 & out1$cpo$failure!=1 & out1$cpo$pit>0.01)
pit2 <- ggplot(data=pit1, aes(x=PIT)) +
  geom_histogram(col="white") +
  xlab("Probability integral transform (PIT)") +
  ylab("Count"); pit2; summary(pit1$PIT)

#print plot and then turn device off
pdf(paste(out.dir, species.list[m], ".PITPlot.pdf", sep=""))
  try(print(pit2, silent=T))
while(!is.null(dev.list())) dev.off()

##-----------------------------------------------------------
#time series plots per cell
#calcualte cell level index of abundance
# cell_ts <- function(cell1=1){
 
#create a loop to get abundance index output per cell-year

for(k in 1:length(cells_with_counts)) {

#k<-1 #for testing each cell
   
  cell1 <-NULL 
  cell1 <- k
  
#need to back assign the factor cell1 to its original grid_id
cell_id<-sp.data %>% ungroup() %>% dplyr::select(grid_id, alpha_i) %>% distinct()
grid1<- as.character(cell_id[k,"grid_id"])
  
   d0 <- out1$summary.random$alpha_i$`0.5quant`[cell1]
   d1 <- out1$summary.random$tau_i$`0.5quant`[cell1]
   d2 <- data.frame(
   styear=as.numeric(gsub(paste0(cell1,"-"), "",
                        grep(paste0("\\b",cell1,"-"),
                             out1$summary.random$gamma_ij$ID,
                                  value=TRUE)))- max.yr,
   gamma_ij=
     out1$summary.random$gamma_ij$`0.5quant`[grep(
       paste0("\\b",cell1,"-"), out1$summary.random$gamma_ij$ID)]) %>%
     arrange(styear)
   d2$x0 <- d0
   d2$x1 <- d2$styear*d1
   d2$abund <- exp(d2$x0 + d2$x1 + d2$gamma_ij)
 # d2$trend <- exp(d2$x0 + d2$x1)
 #   ggplot(d2, aes(x=styear+2019)) + geom_line(aes(y=trend)) +
 #   geom_point(aes(y=abund)) 
   #+label=paste0("Grid cell number ", cell1)

   d3<-d2 %>% select(styear, abund) %>% mutate(year=styear+2019, grid_id=grid1) %>% select(-styear)

write.table(d3, paste(out.dir, species.list[m], "AnnualIndex.csv", sep="."), row.names = FALSE, append = TRUE, quote = FALSE, sep = ",", col.names = TRUE)
   
   } #end cell specific loop
 
#to plot a subset of the cell specific trends and indicies 
# cell2 <- c(1,2,3,4,5)
# for(i in cell2){
#   print(cell_ts(i))
# }

##-----------------------------------------------------------
#Explore posterior samples 
posterior_ss <- 100 # change as appropriate
samp1 <- inla.posterior.sample(posterior_ss, out1, num.threads=3)
par_names <- as.character(attr(samp1[[1]]$latent, "dimnames")[[1]])
post1 <- as.data.frame(sapply(samp1, function(x) x$latent))
post1$par_names <- par_names
 
# tau samples
tau_samps1 <- post1[grep("tau_i", post1$par_names), ]
row.names(tau_samps1) <- NULL
tau_samps1 <- tau_samps1[cells_with_counts, 1:posterior_ss]
tau_samps1 <- (exp(tau_samps1) - 1) * 100
tau_samps2 <- cbind(grid_key[cells_with_counts,], tau_samps1)
row.names(tau_samps2) <- NULL
val_names <- grep("V", names(tau_samps2))

#tau_prov
tau_prov <- tau_samps2 %>%
  ungroup() %>%  #this seems to be needed before the select function or it won't work
  dplyr::select(StateProvince, val_names) %>%
  mutate(StateProvince=factor(StateProvince)) %>%
  gather(key=key, val=val, -StateProvince) %>%
  dplyr::select(-key) %>%
  group_by(StateProvince) %>%
  summarise(med_tau=median(val), lcl_tau=quantile(val, probs=0.025),
            ucl_tau=quantile(val, probs=0.975), iw_tau=ucl_tau-lcl_tau,
            n=n()/posterior_ss); head(tau_prov)
tau_prov$Species <- species.list[m]
  
write.table(tau_prov, paste(out.dir, "Tau_Prov.csv", sep="."), row.names = FALSE, append = TRUE, quote = FALSE, sep = ",", col.names = TRUE)

# alpha samples
alpha_samps1 <- post1[grep("alpha_i", post1$par_names), ]
row.names(alpha_samps1) <- NULL
alpha_samps1 <- alpha_samps1[cells_with_counts, 1:posterior_ss]
alpha_samps1 <- exp(alpha_samps1) 
alpha_samps2 <- cbind(grid_key[cells_with_counts,], alpha_samps1)
row.names(alpha_samps2) <- NULL
val_names <- grep("V", names(alpha_samps2))

#alpha_prov
alpha_prov <- alpha_samps2 %>%
  ungroup() %>%  #this seems to be needed before the select function or it won't work
  dplyr::select(StateProvince, val_names) %>%
  mutate(StateProvince=factor(StateProvince)) %>%
  gather(key=key, val=val, -StateProvince) %>%
  dplyr::select(-key) %>%
  group_by(StateProvince) %>%
  summarise(med_alpha=median(val), lcl_alpha=quantile(val, probs=0.025),
            ucl_alpha=quantile(val, probs=0.975), iw_alpha=ucl_alpha-lcl_alpha,
            n=n()/posterior_ss); head(alpha_prov)
alpha_prov$Species <- species.list[m]
  
write.table(alpha_prov, paste(out.dir, "alpha_Prov.csv", sep="."), row.names = FALSE, append = TRUE, quote = FALSE, sep = ",", col.names = TRUE)

# tau_total
tau_tot <- tau_samps2 %>%
  ungroup() %>% # odd why this is needed. Something isn't working right. 
  dplyr::select(val_names) %>%
  as.matrix() %>%
  as.numeric() %>%
  quantile(probs=c(0.5, 0.025, 0.975)); tau_tot
tau_tot$Species <- species.list[m]

write.table(tau_tot, paste(out.dir, "Tau_Tot.csv", sep="."), row.names = FALSE, append = TRUE, quote = FALSE, sep = ",", col.names = TRUE)

# alpha_total
alpha_tot <- alpha_samps2 %>%
  ungroup() %>% # odd why this is needed. Something isn't working right. 
  dplyr::select(val_names) %>%
  as.matrix() %>%
  as.numeric() %>%
  quantile(probs=c(0.5, 0.025, 0.975)); alpha_tot
alpha_tot$Species <- species.list[m]

write.table(alpha_tot, paste(out.dir, "alpha_Tot.csv", sep="."), row.names = FALSE, append = TRUE, quote = FALSE, sep = ",", col.names = TRUE)


##-----------------------------------------------------------
#Collect posterior summaries into one data frame 
#removed esp

post_sum<-NULL
post_sum <- data.frame(alpha_i=cells_with_counts,
                       alph, alph_ll, alph_ul, alph_iw,
                       #eps, eps_ll, eps_ul, eps_iw, eps_sig=NA,
                       tau, tau_ll, tau_ul, tau_iw, tau_sig=NA)
#post_sum$eps_sig <- ifelse((post_sum$eps_ll < 1 & post_sum$eps_ul > 1),
#                           post_sum$eps_sig <- NA,
#                           post_sum$eps_sig <- post_sum$eps)
post_sum$tau_sig <- ifelse((post_sum$tau_ll < 1 & post_sum$tau_ul > 1),
                           post_sum$tau_sig <- 0,
                           post_sum$tau_sig <- post_sum$tau)

#summary(post_sum)

#need to back assign the factor alpha_id to its original value
id_grid<-sp.data %>% ungroup() %>% dplyr::select(grid_id, alpha_i, StateProvince) %>% distinct()
#names(id_grid)[names(id_grid)=="alpha_i"] <- "id"
#names(post_sum)[names(post_sum)=="alpha_i"]<-"id"
post_sum<-merge(post_sum, id_grid, by="alpha_i")
post_sum$grid_id<-as.character(post_sum$grid_id)
#add number of routes per cell to summary for plotting
route_per_cell$grid_id<-as.character(route_per_cell$grid_id)
post_sum <- left_join(post_sum, route_per_cell, by="grid_id")
post_sum$number_routes[is.na(post_sum$number_routes)] <- 0
post_sum$Species <- species.list[m]

write.csv(post_sum, paste(out.dir, species.list[m], "PosteriorSummary.csv", sep="."))

##-----------------------------------------------------------
#Make cell level maps

# plot theme
theme_timeseries <- function (base_size = 11, base_family = "") {
  theme_grey(base_size = base_size, base_family = base_family) %+replace%
    theme(panel.background = element_rect(fill = "white", colour = NA),
          panel.border = element_rect(fill = NA, colour = "grey20"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          axis.text.x = element_text(size = rel(0.9), angle = 0),
          axis.text.y = element_text(size = rel(0.9), angle = 0),
          strip.background = element_rect(fill = "grey80"),
          legend.key = element_rect(fill = "white", colour = NA),
          plot.title = element_text(size=14, hjust = 0.5,
                                    margin=margin(t=5, b=10)),
          legend.position="right",
          complete = TRUE)
}; theme_set(theme_timeseries())

# map theme
theme_map <- function(base_size = 9, base_family = "") {
  theme_bw(base_size = base_size, base_family = base_family) %+replace%
    theme(axis.line = element_blank(),
          axis.text = element_blank(),
          axis.ticks = element_blank(),
          axis.title = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          panel.grid = element_blank(),
          panel.spacing = unit(0, "lines"),
          plot.background = element_blank(),
          legend.background=element_rect(fill=NA, colour=NA),
          legend.direction="vertical",
          legend.key=element_rect(fill=NA, colour="white"),
          legend.text.align=1,
          legend.text = element_text(size=9),
          legend.title=element_text(hjust=0, size=11),
          legend.justification=c(0, 0.5),
          plot.title = element_text(size=14, hjust = 0.7))
}

#Changed base map to Altantic provinces. 
prov_map<-NULL
prov_map <- readOGR(dsn="C:/Users/dethier/Documents/ethier-scripts/Atlantic-NOS/Data", layer="simple_prov")
prov_sf <- as(prov_map, "sf")
post_sum<-distinct(post_sum) #need to take distinct rows


ATOWLS_Grid@data <- data.frame(ATOWLS_Grid@data, post_sum[match(ATOWLS_Grid@data[,"grid_id"], post_sum[,"grid_id"]),])
res_sf<-NULL
res_sf<-as(ATOWLS_Grid, "sf")
#results_cells <- merge(ATOWLS_Grid, post_sum, by="grid_id", all=F)
#res_sf <- as(results_cells, "sf")
plot(res_sf["tau"])
#ATOWLS_Grid <- ATOWLS_Grid[cells_with_counts, ]
#plot(ATOWLS_Grid)
#will want to fix this so I can plot routes too
#plot(routes, add=T, pch=16, cex=0.5)


base1 <- ggplot() +
  geom_sf(data=prov_sf, fill="gray40", col="gray40") +
  theme_map() + theme(panel.grid.major=element_line(colour="transparent"))

# map route

route_p1 <- ggplot() +
  geom_sf(data=res_sf, aes(fill=number_routes), col="gray40", size=0.3) +
  scale_fill_gradient("A. Routes\nper cell", low = ("white"),
                      high = muted("orange4"), space = "Lab", trans="log1p",
                      na.value = "grey40", guide = "colourbar",
                      breaks=c(0,15,30)) +
  theme_map() +
  theme(panel.grid.major=element_line(colour="transparent"))

# map alpha
alph_p1 <- ggplot() +
  geom_sf(data=res_sf, aes(fill=alph), col="gray40", size=0.3) +
  scale_fill_gradient2("B. Alpha", low = muted("purple4"), mid = "white",
                       high = ("yellow"), midpoint = 0, space = "Lab",
                       na.value = "grey40", guide = "colourbar", trans="log",
                       breaks=c(0.5, 1, 2)) +
  theme_map() + theme(panel.grid.major=element_line(colour="transparent"))

# map tau
tau_p1 <- ggplot() +
  geom_sf(data=res_sf, aes(fill=tau), col="gray40", size=0.3) +
  scale_fill_gradient2("C. Tau\n(% per year)", low = ("royalblue4"),
                       mid = "white",
                       high = ("red4"), midpoint = 0, space = "Lab",
                       na.value = "grey40", guide = "colourbar") +
  theme_map() + theme(panel.grid.major=element_line(colour="transparent"))

tau_p2 <- ggplot() +
  geom_sf(data=res_sf, aes(fill=tau_iw), col="gray40", size=0.3) +
  scale_fill_gradient2("D. Tau\ncredible\ninterval\nwidth\n(% per year)",
                       low = ("purple4"), mid = "white",
                       high = ("green4"), midpoint = 6, space = "Lab",
                       na.value = "grey40", guide = "colourbar",
                       #breaks=c(3,6,9,12)
                       ) +
  theme_map() + theme(panel.grid.major=element_line(colour="transparent"))

tau_p3 <- ggplot() +
  geom_sf(data=res_sf, aes(fill=tau_sig), col="gray40", size=0.3) +
  scale_fill_gradient2("E. Significant\ntau (% per year)",
                       low = muted("royalblue4"), mid = "gray95",
                       high = muted("red4"), midpoint = 0, space = "Lab",
                       na.value = "grey40", guide = "colourbar") +
  theme_map() + theme(panel.grid.major=element_line(colour="transparent"))

#View the multiplot berfore printing
#multiplot(base1, alph_p1, tau_p2, route_p1, tau_p1, tau_p3, cols=2)
 
#print plot and then turn device off

pdf(paste(out.dir, species.list[m], ".MultiMapPlot.pdf", sep=""))
multiplot(base1, alph_p1, tau_p2, route_p1, tau_p1, tau_p3, cols=2)
while(!is.null(dev.list())) dev.off()
 
##----------------------------------------------------------- 
# aggregate results 
# summarise at prov
new_prov <- post_sum %>% 
  group_by(StateProvince) %>%
  summarise(new_med_tau=median(tau), new_med_prec=median(tau_iw),
            new_min_prec=min(tau_iw), new_max_prec=max(tau_iw))
new_prov$Species <- species.list[m]


write.table(new_prov, paste(out.dir, "Tau_Prov_Prec.csv", sep="."), row.names = FALSE, append = TRUE, quote = FALSE, sep = ",", col.names = TRUE)

} #end species loop

```


Support function to calculate the variance sigma from tau (see page 120 Zuur 2017)

alpha<-out1$marginals.hyperpar$'Precision for alpha_i'

tau<-out1$marginals.hyperpar$'Precision for tau_i'


MySqrt <- function(x) {1/sqrt(x)}
sigma <- inla.emarginal(MySqrt, alpha)
sigma

#Tools to check for over dispersion
remotes::install_github("inbo/inlatools")
library(inlatools)

plot(dispersion_check(out1))


#Dispersion Statistic 
mu.op<-out1$summary.fitted.values[,"mean"]
E.op<-(sp.data$count1-mu.op)/ sqrt(mu.op) #Pearson residuals
N<-nrow(sp.data)
p<-nrow(out1$summary.fixed)
Dispersion.op<-sum(E.op^2)/(N-p)
print(paste("Dispersions Statistic Overdispersed = ", Dispersion.op, sep = ""))


